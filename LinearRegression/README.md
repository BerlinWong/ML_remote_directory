# LinearRegression 线性回归

## 代价函数

![J(\theta)=\frac{1}{2m}\sum^{m}_{i=1}{(h_\theta(x^{(i)})-y^{(i)})}^2](https://berlin777-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/CodeCogsEqn%20(2).svg)

其中：

![h_\theta (x) = \theta _0 + \theta _1x_1+\theta _2x_2 + ...](https://berlin777-picgo.oss-cn-shenzhen.aliyuncs.com/picgo/CodeCogsEqn%20(3).svg)

原理：要求出$\theta$，使代价最小，即代表我们拟合出来的方程距离真实值最近。
